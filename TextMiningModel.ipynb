{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>a54325.txt</td>\n",
       "      <td>I strongly urge people to avoid over the count...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>ans1541.txt</td>\n",
       "      <td>There are many causes of shoulder-arm pain as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>a24290.txt</td>\n",
       "      <td>LET YOUR DOG BITE IT AND  SWING ON IT FOR 6 MO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>a24335.txt</td>\n",
       "      <td>i have the same problem and have been told hat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>ans1325.txt</td>\n",
       "      <td>The causes of back pain can usually be diagnos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>a24531.txt</td>\n",
       "      <td>Excercise more than you eat! Eat foods low in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>a7451.txt</td>\n",
       "      <td>I wouldnt mind knowing the answer to this ques...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>a24439.txt</td>\n",
       "      <td>If I know what it is thats stressing me out, I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>a24674.txt</td>\n",
       "      <td>The best way is to get them all together and j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>a69406.txt</td>\n",
       "      <td>Awwwww, poor baby - that sounds painful - GOOD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>ans1323.txt</td>\n",
       "      <td>The cause of your throat pain could be due to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>a61484.txt</td>\n",
       "      <td>Let him leave you and laugh at him.\\n\\nHes a j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>ans1318.txt</td>\n",
       "      <td>The car accidents usually produce pain in neck...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>ans583.txt</td>\n",
       "      <td>I would not suggest you to alter the dosage of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>ans767.txt</td>\n",
       "      <td>It is recommended additional imaging studies i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>a61236.txt</td>\n",
       "      <td>Doesnt sound so great to me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>ans1265.txt</td>\n",
       "      <td>Thank you for your question. This sensation yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>ans1283.txt</td>\n",
       "      <td>Thank you for your question. What you have des...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                                               text  class\n",
       "919    a54325.txt  I strongly urge people to avoid over the count...      0\n",
       "603   ans1541.txt  There are many causes of shoulder-arm pain as ...      1\n",
       "58     a24290.txt  LET YOUR DOG BITE IT AND  SWING ON IT FOR 6 MO...      0\n",
       "103    a24335.txt  i have the same problem and have been told hat...      0\n",
       "363   ans1325.txt  The causes of back pain can usually be diagnos...      1\n",
       "299    a24531.txt  Excercise more than you eat! Eat foods low in ...      0\n",
       "1664    a7451.txt  I wouldnt mind knowing the answer to this ques...      0\n",
       "207    a24439.txt  If I know what it is thats stressing me out, I...      0\n",
       "442    a24674.txt  The best way is to get them all together and j...      0\n",
       "1274   a69406.txt  Awwwww, poor baby - that sounds painful - GOOD...      0\n",
       "361   ans1323.txt  The cause of your throat pain could be due to ...      1\n",
       "1184   a61484.txt  Let him leave you and laugh at him.\\n\\nHes a j...      0\n",
       "355   ans1318.txt  The car accidents usually produce pain in neck...      1\n",
       "1412   ans583.txt  I would not suggest you to alter the dosage of...      1\n",
       "1616   ans767.txt  It is recommended additional imaging studies i...      1\n",
       "939    a61236.txt                    Doesnt sound so great to me...       0\n",
       "296   ans1265.txt  Thank you for your question. This sensation yo...      1\n",
       "316   ans1283.txt  Thank you for your question. What you have des...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a pandas dataframe\n",
    "import os\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open(path+f, 'r', encoding='utf-8', errors='ignore') \n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return(pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "dfneg = data2df('HealthProNonPro/NonPro/', 0) # NEG\n",
    "dfpos = data2df('HealthProNonPro/Pro/', 1) # POS\n",
    "\n",
    "df = pd.concat([dfpos, dfneg], axis=0)\n",
    "df.sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(doc):\n",
    "\n",
    "    # clean up text\n",
    "    tokens = [token.lemma_.lower() # lemmatize and lower-case \n",
    "                        for token in doc \n",
    "                               if (\n",
    "                                    len(token) >= 2 and # only preserve tokens that are 2 or more characters long\n",
    "                                    # token.pos_ in ['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV'] and # only preserve specific pos\n",
    "                                    # token.text in nlp.vocab and # check if token in vocab\n",
    "                                    #token.is_alpha and # only preserve tokens that are fully alpha (not numeric or alpha-numeric)\n",
    "                                    #not token.is_digit and # get rid of tokens that are fully numeric\n",
    "                                    not token.is_punct and # get rid of tokens that are punctuations\n",
    "                                    not token.is_space and # get rid of tokens that are spaces\n",
    "                                    not token.is_stop # get rid of tokens that are stop words\n",
    "                                )\n",
    "                   ]\n",
    "\n",
    "    # return cleaned-up text\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data\n",
    "X, y = df['text'], df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "Xtrain = Xtrain.copy()\n",
    "Xtest = Xtest.copy()\n",
    "ytrain = ytrain.copy()\n",
    "ytest = ytest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    accept beatiful mind good course get help wieg...\n",
       "1                           yes diet aerobic anaerobic\n",
       "2    cause feel weak diverse muscle problem polymyo...\n",
       "3    condition totally unrelated blood pus discharg...\n",
       "4    high dose steroid certainly lead sleep problem...\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use spacy to preprocess the train data\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "corpus = nlp.pipe(list(Xtrain))\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtrain = pd.Series(clean_corpus)\n",
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the preprocessing->model pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        binary=False, # tf - bow\n",
    "        #sublinear_tf=False, \n",
    "        use_idf=True, smooth_idf=True, # idf  - with smoothing\n",
    "        norm='l2', # tfidf - l2 norm\n",
    "        #lowercase=True, stop_words='english', \n",
    "        #token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', \n",
    "        min_df=1, max_df=1.0, max_features=None, \n",
    "        ngram_range=(1, 1)\n",
    "    )),\n",
    "    ('np', MultinomialNB(\n",
    "        #alpha=1.0, # laplace add-one smoothing\n",
    "        fit_prior=True, # learn class prior-probabilities from data\n",
    "        class_prior=None # none - go with whatever fit-prior says\n",
    "    )) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grid search with cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'np__alpha':[0.01, 0.1, 0.5, 1],\n",
    "    'tfidf__sublinear_tf':[True, False]\n",
    "}\n",
    "\n",
    "gscv = GridSearchCV(clf, param_grid, iid=False, cv=4, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=1.0, max_features=None,\n",
      "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('np',\n",
      "                 MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))],\n",
      "         verbose=False) \n",
      "\n",
      "0.9388661202185793 \n",
      "\n",
      "{'np__alpha': 0.1, 'tfidf__sublinear_tf': False} \n",
      "\n",
      "{'mean_fit_time': array([0.333561  , 0.26784861, 0.29408169, 0.29383337, 0.30982316,\n",
      "       0.27659255, 0.32081681, 0.32531542]), 'std_fit_time': array([0.0645709 , 0.02471448, 0.03473803, 0.03984643, 0.0440875 ,\n",
      "       0.01519633, 0.02170142, 0.05750088]), 'mean_score_time': array([0.09919387, 0.07070863, 0.08894843, 0.10668826, 0.09469593,\n",
      "       0.08919883, 0.08844924, 0.09794325]), 'std_score_time': array([0.0133589 , 0.00697364, 0.00757869, 0.04583889, 0.01243003,\n",
      "       0.00959575, 0.01618482, 0.02240322]), 'param_np__alpha': masked_array(data=[0.01, 0.01, 0.1, 0.1, 0.5, 0.5, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tfidf__sublinear_tf': masked_array(data=[True, False, True, False, True, False, True, False],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'np__alpha': 0.01, 'tfidf__sublinear_tf': True}, {'np__alpha': 0.01, 'tfidf__sublinear_tf': False}, {'np__alpha': 0.1, 'tfidf__sublinear_tf': True}, {'np__alpha': 0.1, 'tfidf__sublinear_tf': False}, {'np__alpha': 0.5, 'tfidf__sublinear_tf': True}, {'np__alpha': 0.5, 'tfidf__sublinear_tf': False}, {'np__alpha': 1, 'tfidf__sublinear_tf': True}, {'np__alpha': 1, 'tfidf__sublinear_tf': False}], 'split0_test_score': array([0.94672131, 0.94535519, 0.94808743, 0.94945355, 0.94808743,\n",
      "       0.94535519, 0.93715847, 0.93579235]), 'split1_test_score': array([0.93032787, 0.93169399, 0.93442623, 0.93442623, 0.92349727,\n",
      "       0.92622951, 0.92076503, 0.91939891]), 'split2_test_score': array([0.93579235, 0.93715847, 0.94672131, 0.94672131, 0.94125683,\n",
      "       0.94535519, 0.93442623, 0.93442623]), 'split3_test_score': array([0.92213115, 0.92486339, 0.92076503, 0.92486339, 0.91803279,\n",
      "       0.91803279, 0.91256831, 0.91256831]), 'mean_test_score': array([0.93374317, 0.93476776, 0.9375    , 0.93886612, 0.93271858,\n",
      "       0.93374317, 0.92622951, 0.92554645]), 'std_test_score': array([0.00893217, 0.0075059 , 0.01102989, 0.00986898, 0.01234715,\n",
      "       0.01196818, 0.01003889, 0.00987489]), 'rank_test_score': array([4, 3, 2, 1, 6, 4, 7, 8])} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# search for best parameters/estimator using train data\n",
    "gscv.fit(Xtrain, ytrain)\n",
    "\n",
    "print(gscv.best_estimator_, \"\\n\")\n",
    "print(gscv.best_score_, \"\\n\")\n",
    "print(gscv.best_params_, \"\\n\")\n",
    "print(gscv.cv_results_, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  ummm sure like wear\n",
       "1    middle ear connect throat tube like structure ...\n",
       "2    trans fat type fat distinct type appear human ...\n",
       "3    take contraceptive pill period delay prolong m...\n",
       "4    urine pregnancy test best week sexual act advi...\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use spacy to preprocess the test data\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "corpus = nlp.pipe(list(Xtest))\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtest = pd.Series(clean_corpus)\n",
    "Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937244201909959\n",
      "[[308  39]\n",
      " [  7 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       347\n",
      "           1       0.91      0.98      0.94       386\n",
      "\n",
      "    accuracy                           0.94       733\n",
      "   macro avg       0.94      0.93      0.94       733\n",
      "weighted avg       0.94      0.94      0.94       733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate best_estimator_ on test data\n",
    "ypred = gscv.best_estimator_.predict(Xtest)\n",
    "\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n",
      "308 39 7 379\n",
      "0.98 0.89 0.93\n",
      "0.91 0.98 0.94\n"
     ]
    }
   ],
   "source": [
    "# deriving the various metrics above:\n",
    "#\n",
    "# if for label=1:\n",
    "#\n",
    "#                    predicted\n",
    "#                   0           1\n",
    "# actual  0    478        52\n",
    "#            1    4             565\n",
    "#\n",
    "# then:\n",
    "#  - tn, fp, fn, tp = 478, 52, 4, 565\n",
    "#  - precision, recall, f1score= 0.92, 0.99, 0.95\n",
    "#\n",
    "\n",
    "# unravel confusion matrix \n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_true=ytest, y_pred=ypred).ravel()\n",
    "\n",
    "# overall accuracy\n",
    "accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "\n",
    "# label 0 metrics\n",
    "precision0 = tn/(tn + fn)\n",
    "recall0 = tn/(tn + fp)\n",
    "f1score0 = 2*tn/(2*tn + fp + fn)\n",
    "support0 = tn + fp\n",
    "\n",
    "# label 1 metrics\n",
    "precision1 = tp/(tp + fp)\n",
    "recall1 = tp/(tp + fn)\n",
    "f1score1 = 2*tp/(2*tp + fp + fn)\n",
    "support1 = tp + fn\n",
    "\n",
    "# micro average matrics - calcualted globally by counting total tn, fp, fn, tp\n",
    "# microprecision = (tn + tp)/(tn + fn + tp + fp)\n",
    "# microrecall = (tn + tp)/(tn + fp + tp + fn)\n",
    "# microf1score = (2*tn + 2*tp)/(2*tn + fp + fn + 2*tp + fp + fn)\n",
    "# microsupport = tp + tn + fp + fn\n",
    "\n",
    "# macro average metrics - average of individual metrics\n",
    "# macroprecision = (precision0+precision1)/2\n",
    "# macrorecall = (recall0+recall1)/2\n",
    "# macrof1score = (f1score0+f1score1)/2\n",
    "# macrosupport = tp + tn + fp + fn \n",
    "\n",
    "# print all \n",
    "print (round(accuracy,2))\n",
    "print (tn, fp, fn, tp)\n",
    "print (round(precision0,2), round(recall0,2), round(f1score0,2)) #, support0)\n",
    "print (round(precision1,2), round(recall1,2), round(f1score1,2)) #, support1)\n",
    "# print (round(macroprecision,2), round(microrecall,2), round(microf1score,2), microsupport)\n",
    "# print (round(macroprecision,2), round(macrorecall,2), round(macrof1score,2), macrosupport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
