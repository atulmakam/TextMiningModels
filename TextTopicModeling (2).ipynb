{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### text topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    : VirtualGrabKeys is not an OW resource. It be...\n",
       "1    \\nHell, just save your candle stubs and bring ...\n",
       "2    \\n   ...  So how about this?  Give the winning...\n",
       "3    I ONLY Just prevented myself from diving  in o...\n",
       "4    A few days ago there was a posting in this gro...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/datasets/index.html#newsgroups-dataset\n",
    "# http://qwone.com/~jason/20Newsgroups/\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n",
    "from sklearn.datasets.twenty_newsgroups import fetch_20newsgroups\n",
    "\n",
    "# load full data set; strip posts of headers, footers and quoted replies; pick all categories\n",
    "data = fetch_20newsgroups(\n",
    "    subset='all', # subset='train',         \n",
    "    categories=['sci.space', 'rec.motorcycles','comp.windows.x'],\n",
    "    remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# convert data to dataframe\n",
    "newsgroup20df = pd.DataFrame(data.data, columns=['content'])\n",
    "newsgroup20df['target'] = data.target\n",
    "newsgroup20df['target_names'] = newsgroup20df['target'].apply(lambda x: data.target_names[x])\n",
    "# newsgroup20df.head()\n",
    "# newsgroup20df['target_names'].value_counts()\n",
    "\n",
    "X, y = newsgroup20df['content'], newsgroup20df['target']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>: VirtualGrabKeys is not an OW resource. It be...</td>\n",
       "      <td>0</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\\nHell, just save your candle stubs and bring ...</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n   ...  So how about this?  Give the winning...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I ONLY Just prevented myself from diving  in o...</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A few days ago there was a posting in this gro...</td>\n",
       "      <td>0</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target     target_names\n",
       "0  : VirtualGrabKeys is not an OW resource. It be...       0   comp.windows.x\n",
       "1  \\nHell, just save your candle stubs and bring ...       1  rec.motorcycles\n",
       "2  \\n   ...  So how about this?  Give the winning...       2        sci.space\n",
       "3  I ONLY Just prevented myself from diving  in o...       1  rec.motorcycles\n",
       "4  A few days ago there was a posting in this gro...       0   comp.windows.x"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroup20df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.motorcycles    996\n",
       "comp.windows.x     988\n",
       "sci.space          987\n",
       "Name: target_names, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroup20df['target_names'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LDA #####\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "# Latent Dirichlet Allocation is a generative probabilistic model for collections of discrete dataset such as text corpora. \n",
    "# It is also a topic model that is used for discovering abstract topics from a collection of documents.\n",
    "\n",
    "# LDA is an iterative algorithm. \n",
    "# Initially, each word is assigned to a random topic.\n",
    "# Then, in each iteration, the algorithm reassigns each word to a topic based on \n",
    "#    the probability of the word belonging to a topic,\n",
    "#    and the probability of the document generated by a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "n_docs = X.shape[0] \n",
    "n_features = 1000          \n",
    "n_components = 3 # number of topics T\n",
    "doc_topic_prior = 50/n_components # alpha\n",
    "topic_word_prior = 0.01 # beta\n",
    "n_top_words = 20\n",
    "\n",
    "# n_top_terms = 2\n",
    "# arr = np.array([10, 20, 40, 5, 30])\n",
    "# print (arr.argsort())\n",
    "# print (arr.argsort()[::-1])\n",
    "# print (arr.argsort()[:-n_top_terms-1:-1])\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(doc):\n",
    "\n",
    "    # use spacy to filter out noise\n",
    "    tokens = [token.lemma_.lower() \n",
    "                        for token in doc \n",
    "                               if (\n",
    "                                    len(token) >= 2 and # only preserve tokens that are greater than 2 characters long\n",
    "                                    token.pos_ in ['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV'] and # only preserve selected pos\n",
    "                                    #token.text in nlp.vocab and # check if token in vocab \n",
    "                                    token.is_alpha and # only preserve tokens that are fully alpha (not numeric or alpha-numeric)\n",
    "                                    #not token.is_digit and # get rid of tokens that are fully numeric\n",
    "                                    not token.is_punct and # get rid of tokens that are punctuations\n",
    "                                    not token.is_space and # get rid of tokens that are spaces\n",
    "                                    not token.is_stop and # get rid of tokens that are stop words\n",
    "                                    not token.is_currency # get rid of tokens that denote currencies\n",
    "                                )\n",
    "                   ]\n",
    "\n",
    "    # return cleaned-up text\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    virtualgrabkeys ow resource belong man page sa...\n",
       "1    save candle stub bring light dribble wax kindl...\n",
       "2    win group company corp year moratorium taxis t...\n",
       "3                                         prevent dive\n",
       "4    day ago posting group andrea winkler title sec...\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "corpus = nlp.pipe(list(X))\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "X = pd.Series(clean_corpus)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW Term Frequency using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activity</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>xdm</th>\n",
       "      <th>xlib</th>\n",
       "      <th>xmu</th>\n",
       "      <th>xt</th>\n",
       "      <th>xterm</th>\n",
       "      <th>xv</th>\n",
       "      <th>xview</th>\n",
       "      <th>xvoid</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Doc0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  accept  access  act  action  activity  actually   ad  \\\n",
       "Doc0      0.0   0.0     0.0     0.0  0.0     0.0       0.0       0.0  0.0   \n",
       "Doc1      0.0   0.0     0.0     0.0  0.0     0.0       0.0       0.0  0.0   \n",
       "Doc2      0.0   0.0     0.0     0.0  0.0     0.0       0.0       0.0  0.0   \n",
       "Doc3      0.0   0.0     0.0     0.0  0.0     0.0       0.0       0.0  0.0   \n",
       "Doc4      0.0   0.0     0.0     0.0  0.0     0.0       0.0       0.0  0.0   \n",
       "\n",
       "      add  ...  wrong  xdm  xlib  xmu   xt  xterm   xv  xview  xvoid  year  \n",
       "Doc0  0.0  ...    0.0  0.0   0.0  0.0  0.0    0.0  0.0    0.0    0.0   0.0  \n",
       "Doc1  0.0  ...    0.0  0.0   0.0  0.0  0.0    0.0  0.0    0.0    0.0   0.0  \n",
       "Doc2  0.0  ...    0.0  0.0   0.0  0.0  0.0    0.0  0.0    0.0    0.0   1.0  \n",
       "Doc3  0.0  ...    0.0  0.0   0.0  0.0  0.0    0.0  0.0    0.0    0.0   0.0  \n",
       "Doc4  0.0  ...    0.0  0.0   0.0  0.0  0.0    0.0  0.0    0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda can only use raw counts \n",
    "\n",
    "# init bow model\n",
    "bow = TfidfVectorizer(\n",
    "    binary=False, norm=None, # tf - bow\n",
    "    use_idf=False, smooth_idf=False, # idf - none\n",
    "    lowercase=True, stop_words='english', \n",
    "    min_df=2, max_df=0.95, max_features=n_features, \n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "# fit bow model with data\n",
    "bow_model = bow.fit(X)\n",
    "feature_names = bow_model.get_feature_names()\n",
    "\n",
    "# transform data\n",
    "bow_trans = bow_model.transform(X)\n",
    "\n",
    "# let's take a look at the doc-term matrix\n",
    "DocTermMatrix = pd.DataFrame(data=bow_trans.toarray(), \n",
    "             index = ['Doc' + str(i) for i in range(n_docs)],\n",
    "             columns = feature_names)\n",
    "DocTermMatrix.head() # n_docs, n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activity</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>xdm</th>\n",
       "      <th>xlib</th>\n",
       "      <th>xmu</th>\n",
       "      <th>xt</th>\n",
       "      <th>xterm</th>\n",
       "      <th>xv</th>\n",
       "      <th>xview</th>\n",
       "      <th>xvoid</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Topic0</td>\n",
       "      <td>19.8498</td>\n",
       "      <td>75.6686</td>\n",
       "      <td>8.2712</td>\n",
       "      <td>18.6551</td>\n",
       "      <td>49.6337</td>\n",
       "      <td>8.1282</td>\n",
       "      <td>97.8260</td>\n",
       "      <td>44.8920</td>\n",
       "      <td>45.7311</td>\n",
       "      <td>35.8606</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0058</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>397.2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic1</td>\n",
       "      <td>28.3355</td>\n",
       "      <td>76.2608</td>\n",
       "      <td>26.1547</td>\n",
       "      <td>124.2753</td>\n",
       "      <td>12.5880</td>\n",
       "      <td>54.6487</td>\n",
       "      <td>3.7558</td>\n",
       "      <td>71.8657</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>211.4134</td>\n",
       "      <td>...</td>\n",
       "      <td>28.4953</td>\n",
       "      <td>95.0492</td>\n",
       "      <td>136.9066</td>\n",
       "      <td>57.3642</td>\n",
       "      <td>185.6525</td>\n",
       "      <td>273.3357</td>\n",
       "      <td>27.0337</td>\n",
       "      <td>170.9821</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>4.9873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Topic2</td>\n",
       "      <td>2.8908</td>\n",
       "      <td>41.3794</td>\n",
       "      <td>21.8202</td>\n",
       "      <td>12.3623</td>\n",
       "      <td>2.2161</td>\n",
       "      <td>22.5933</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>89.1645</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>16.6746</td>\n",
       "      <td>...</td>\n",
       "      <td>71.1026</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>4.0156</td>\n",
       "      <td>2.0672</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>7.7362</td>\n",
       "      <td>51.6930</td>\n",
       "      <td>0.2648</td>\n",
       "      <td>48.0701</td>\n",
       "      <td>196.8194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ability     able   accept    access      act   action  activity  \\\n",
       "Topic0  19.8498  75.6686   8.2712   18.6551  49.6337   8.1282   97.8260   \n",
       "Topic1  28.3355  76.2608  26.1547  124.2753  12.5880  54.6487    3.7558   \n",
       "Topic2   2.8908  41.3794  21.8202   12.3623   2.2161  22.5933    0.3525   \n",
       "\n",
       "        actually       ad       add  ...    wrong      xdm      xlib      xmu  \\\n",
       "Topic0   44.8920  45.7311   35.8606  ...  16.0058   0.0603    0.0446   0.0610   \n",
       "Topic1   71.8657   0.0712  211.4134  ...  28.4953  95.0492  136.9066  57.3642   \n",
       "Topic2   89.1645   0.4091   16.6746  ...  71.1026   0.2593    4.0156   2.0672   \n",
       "\n",
       "              xt     xterm       xv     xview    xvoid      year  \n",
       "Topic0    0.0264    0.1754   0.7441    0.0225   0.0111  397.2930  \n",
       "Topic1  185.6525  273.3357  27.0337  170.9821   0.0115    4.9873  \n",
       "Topic2    0.1483    7.7362  51.6930    0.2648  48.0701  196.8194  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init lda model\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_components, \n",
    "    doc_topic_prior=doc_topic_prior,\n",
    "    topic_word_prior=topic_word_prior,\n",
    "    learning_method='online', \n",
    "    learning_offset=50,\n",
    "    random_state=1) \n",
    "\n",
    "# fit lda model with data\n",
    "# lda_model.components_: \n",
    "# Since the complete conditional for topic word distribution is a Dirichlet, \n",
    "#    components_[i, j] can be viewed as pseudocount that represents the number of times word j was assigned to topic i. \n",
    "# It can also be viewed as distribution over the words for each topic after normalization: \n",
    "#    model.components_ / model.components_.sum(axis=1)[:, np.newaxis].\n",
    "lda_model = lda.fit(bow_trans)\n",
    "\n",
    "# let's take a look at the topic-term matrix\n",
    "TopicTermMatrix = pd.DataFrame(data=np.round(lda_model.components_, 4), \n",
    "             index = ['Topic' + str(i) for i in range(n_components)],\n",
    "             columns = feature_names)\n",
    "TopicTermMatrix.head() # n_topics, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: space launch time year earth nasa orbit mission satellite shuttle moon new cost think know solar spacecraft planet design large\n",
      "Topic #1: window use server run widget application include available file support set version display work motif program user look sun software\n",
      "Topic #2: file bike know program entry need think good use try line ride way want thing time read right people build\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's take a look at the top words in each topic\n",
    "print_top_words(lda_model, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Doc0</td>\n",
       "      <td>0.3244</td>\n",
       "      <td>0.3521</td>\n",
       "      <td>0.3236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc1</td>\n",
       "      <td>0.3212</td>\n",
       "      <td>0.2922</td>\n",
       "      <td>0.3866</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc2</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.3002</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc3</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc4</td>\n",
       "      <td>0.3252</td>\n",
       "      <td>0.3022</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  dominant_topic\n",
       "Doc0  0.3244  0.3521  0.3236               1\n",
       "Doc1  0.3212  0.2922  0.3866               2\n",
       "Doc2  0.3509  0.3002  0.3489               0\n",
       "Doc3  0.3333  0.3333  0.3333               0\n",
       "Doc4  0.3252  0.3022  0.3726               2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform data\n",
    "lda_trans = lda_model.transform(bow_trans)\n",
    "\n",
    "# let's take a look at the doc-topic matrix.\n",
    "# note that the each document is now represented in terms of the underlying latent topics.\n",
    "# the numbers represent how much of  the document was generated by which topic, and add up to 1.\n",
    "DocTopicMatrix = pd.DataFrame(data=np.round(lda_trans, 4), \n",
    "             index = ['Doc' + str(i) for i in range(n_docs)],\n",
    "             columns = ['Topic' + str(i) for i in range(n_components)])\n",
    "DocTopicMatrix.head() # n_docs, n_topics\n",
    "\n",
    "# let's also include the dominant topic in each document \n",
    "DocTopicMatrix['dominant_topic'] = np.argmax(DocTopicMatrix.values, axis=1)\n",
    "DocTopicMatrix.head() # n_docs, n_topics + 1 col for dominant topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659.6462105275187"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perplexity: a measure of how genralizable the model is. lower the score, the better.\n",
    "lda_model.perplexity(bow_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1106\n",
       "0     978\n",
       "1     887\n",
       "Name: dominant_topic, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's the distribution of topics\n",
    "DocTopicMatrix['dominant_topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a good topic model will have big, non-overlapping clusters for each topic. \n",
    "\n",
    "# pip install pyLDAvis\n",
    "# import pyLDAvis.sklearn\n",
    " \n",
    "# pyLDAvis.enable_notebook()\n",
    "# panel = pyLDAvis.sklearn.prepare(lda_model, bow_trans, bow, mds='tsne')\n",
    "# panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant Topic Index:\n",
      " 0\n",
      "Dominant Topic Terms:\n",
      " ability     19.8498\n",
      "able        75.6686\n",
      "accept       8.2712\n",
      "access      18.6551\n",
      "act         49.6337\n",
      "             ...   \n",
      "xterm        0.1754\n",
      "xv           0.7441\n",
      "xview        0.0225\n",
      "xvoid        0.0111\n",
      "year       397.2930\n",
      "Name: Topic0, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# predict topic given some text\n",
    "text = \"NASA is an independent agency responsible for the civilian space program.\"\n",
    "text_topic_scores = lda_model.transform(bow_model.transform([text]))\n",
    "dominant_topic_index = text_topic_scores.argmax()\n",
    "dominant_topic_terms = TopicTermMatrix.iloc[dominant_topic_index, :]\n",
    "print (\"Dominant Topic Index:\\n\", dominant_topic_index)\n",
    "print (\"Dominant Topic Terms:\\n\", dominant_topic_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36490317, 0.3156024 , 0.31949443]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.transform(bow_model.transform([text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
